{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Daniela Gonzalez Favero\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Daniela Gonzalez Favero\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2021)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> and Lecture 03 of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n",
    "**Now we will explore this model, starting with a simple dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset \n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44262.23, sdt 16158.33, max 77388.89, min 17528.95\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ be a matrix (sometimes also called the *design matrix*) whose rows are the observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{x}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "Using only **NumPy** (a quick introduction to this library can be found  [here](http://cs231n.github.io/python-numpy-tutorial/)), complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    N, d = np.shape(X)\n",
    "    X_new = np.hstack((np.ones((N, 1)), X)) # adds into X a new column with 1s\n",
    "    \n",
    "    X_transposed = np.transpose(X_new) \n",
    "    X_new = np.matmul(X_transposed, X_new) # X = XT * X\n",
    "    X_new = np.linalg.inv(X_new) # X = X^{-1}\n",
    "    X_new = np.matmul(X_new, X_transposed) # X = X * XT\n",
    "    \n",
    "    return np.matmul(X_new, y) # w = X * y\n",
    "    # END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[12872.06110813]\n",
      " [   48.66693063]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    N, d = np.shape(X)\n",
    "    X_new = np.hstack((np.ones((N, 1)), X)) # adds into X a new column with 1s\n",
    "    \n",
    "    return np.matmul(X_new, w) # y = X * w\n",
    "    # END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $𝑅^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = 0\n",
    "# END OF YOUR CODE\n",
    "\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different nummber of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [100] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "Let us test the code with $𝑑>1$. \n",
    "We will use the data we have collected in our first class. The [file](https://edisciplinas.usp.br/pluginfile.php/5982803/course/section/6115454/QT1data.csv) can be found on e-disciplinas. \n",
    "\n",
    "Let us try to predict the weight based on one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv('QT1data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target variable is the weight\n",
    "y = df.pop('Weight').values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise with using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used. There is no need to do plotting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.4 - Your comments</mark>\n",
    "\n",
    "Did you observe anything interesting with varying values of $d$ ? Comment about it.\n",
    "\n",
    "YOUR COMMENT BELOW:\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
